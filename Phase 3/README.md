## PHASE 2 : REAL ROBOTICS

### Lecture Titles :

- `1. Reinforcement Learning Basics: Markov Decision Processes, Deterministic, and Stochastic Environments & Bellman Equation`

- `2. Q-Learning: Q-Learning, Plan vs Policy Networks, and Environment Models`

- `3. Deep Q-Learning & DeepTraffic: Custom Environments, OpenGym, Exploration vs Exploitation, and improvements to DQN`

- `4. Deep Reinforcement Learning: Policy Gradients, Dynamic Programming, Policy Evaluations, and Temporal Difference Learning`

- `5. Actor-Critic Models: Memory Structures, Gibbs Softmax, Eligibility Traces, and Polyak Averaging`

- `6. A3C Models: A3C, A3C optimizations,, and implementation logic`

- `7. Deep Deterministic Policy Gradients: DDPG Background, Off-Policy Networks, Continuous Action Spaces, and Replay Buffers`

- `8. Twin Delayed DDPG Part 1: Clipped Double-Q Learning, Delayed Policy Updates, and Target Policy Smoothing`

- `9. Twin Delayed DDPG Part 2: Full TD3 implementation to make a robot walk, and solve a custom environment`

- `10. Autonomous Robotics Introduction: Introduction to ARI platform, and its control systems. Real Robot we mean!`

- `11. Sensor Fusion for Localization: Sensor fusion, depth estimation, and stereo imaging for robotic localization`

- `12. 3D Environmental Reconstruction Part 1: Solving 3D mapping for static environment`

- `13. 3D Environmental Reconstruction Part 2: Solving 3D mapping for dynamic (moving) objects in the static environment`

- `14. 3D Environmental Reconstruction Part 3: Solving 3D mapping for dynamic objects in a dynamic environment`

- `15. Advanced Path planning, and Navigation: A*, and other Path planning, and algorithms`

- `16. EndGame: CapStone project to implement everything we learned`

***`The later part of this course's topics are inspired from Udacity Nanodegree but only just the topics, not its contents. We would be implementing these on a real robot, without ROS, and using TD3, not DQN as in Udacity`***
